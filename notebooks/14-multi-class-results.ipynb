{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8a26ee",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9214dc7-bdb4-4434-9355-e4ac271793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys \n",
    "sys.path.append('/home/21576262@su/masters/src')\n",
    "from data.data_loading import define_transforms, split_data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.utils.data as data_utils\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82bf5b-261c-4119-bf1b-a35065897979",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0957be-f072-40ba-a57e-d4aac92301ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE=256\n",
    "STRIDE=PATCH_SIZE\n",
    "SEED=42\n",
    "num_cpus=4\n",
    "num_classes=2\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "model_name = 'resnet'\n",
    "\n",
    "ResNet = True if model_name == 'resnet' else False\n",
    "Inception = True if model_name == 'inception' else False\n",
    "\n",
    "if Inception:\n",
    "        INPUT_SIZE=299\n",
    "elif ResNet:\n",
    "    INPUT_SIZE=224\n",
    "else:\n",
    "    INPUT_SIZE=PATCH_SIZE\n",
    "\n",
    "print(ResNet, Inception)\n",
    "\n",
    "# using full set of data\n",
    "img_dir = '/home/21576262@su/masters/data/patches/'\n",
    "labels_dir = '/home/21576262@su/masters/data/labels/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc62f32-534e-4b0b-b61a-086ec1f2e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetMulti(Dataset):\n",
    "    def __init__(self, img_folders, label_files, transform=None):\n",
    "        self.img_folders = img_folders\n",
    "        self.label_files = label_files\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs = [] # Keeps image paths to load in the __getitem__ method\n",
    "        self.labels = []\n",
    "        self.cases = [] # All cases in this set\n",
    "        self.img_cases=[] # Image case for each patch\n",
    "        self.HER2_labels = []\n",
    "\n",
    "        df_her2_status = get_her2_status_list()\n",
    "\n",
    "        # Load images and corresponding labels\n",
    "        for i, (img_folder, label_file) in enumerate(zip(img_folders, label_files)):\n",
    "            # print(\"Patch directory\", img_folder, \"\\nLabel file\", label_file)\n",
    "            labels_pt = torch.load(label_file) # Load .pt file\n",
    "            self.cases.append(img_folder.split('/')[-1])\n",
    "            # Run through all patches from the case folder\n",
    "            for i, img in enumerate(os.listdir(img_folder)):\n",
    "                if os.path.isfile(os.path.join(img_folder, img)) and os.path.isfile(label_file):\n",
    "                    # print(img_folder + img)\n",
    "                    case_id = img_folder.split('/')[-1]\n",
    "                    self.img_cases.append(case_id)\n",
    "                    if img.startswith('._'):\n",
    "                        img = img.replace('._', '')\n",
    "                    idx = int(img.replace('.png', '').split(\"_\")[1])\n",
    "                    self.imgs.append(os.path.join(img_folder, img))\n",
    "                    self.labels.append(labels_pt[idx].item()) # get label as int\n",
    "                    if labels_pt[idx].item() == 1: # if tile is cancerous\n",
    "                        self.HER2_labels.append(df_her2_status[case_id])\n",
    "                    else: # if not tumorous, there is no HER2 label\n",
    "                        self.HER2_labels.append(0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image at given index\n",
    "        image_path = self.imgs[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None: # Apply transformations\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx] # Load corresponding image label\n",
    "\n",
    "        her2_label = self.HER2_labels[idx]\n",
    "        \n",
    "        return image, label, her2_label # Return transformed image and label\n",
    "\n",
    "class RandomSpecificRotation:\n",
    "    def __init__(self, probability=0.5):\n",
    "        self.probability = probability\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Randomly decide whether to apply the rotation or not based on the probability\n",
    "        if random.random() < self.probability:\n",
    "            # Choose a random rotation angle from 90, 180, or 270 degrees\n",
    "            angle = random.choice([90, 180, 270])\n",
    "\n",
    "            # Apply the rotation to the image\n",
    "            img = TF.rotate(img, angle)\n",
    "\n",
    "        return img\n",
    "\n",
    "def get_her2_status_list():\n",
    "\n",
    "    # file_path = '/Users/alexandrasmith/Desktop/Workspace/Projects/masters/data/raw/HER2DataInfo.xlsx'\n",
    "    file_path = '/home/21576262@su/masters/data/HER2DataInfo.xlsx'\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    df.drop(df.index[-2:], inplace=True)\n",
    "\n",
    "    df['Case ID'] = df['Case ID'].str.replace('TCGA-','')\n",
    "    df['Case ID'] = df['Case ID'].str.replace('-01Z-00-DX1','')\n",
    "\n",
    "    df['Clinical.HER2.status'] = df['Clinical.HER2.status'].map({'Negative': 1, 'Positive': 2}).astype(int)\n",
    "\n",
    "    dictt = df.set_index('Case ID').to_dict()['Clinical.HER2.status']\n",
    "\n",
    "    return dictt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdce17c-2856-42fb-b903-65f2e0d7c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = define_transforms(PATCH_SIZE, isResNet=ResNet, isInception=Inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d8cce2-1e7b-45d7-9db9-89967cf54a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise data transforms\n",
    "if Inception:\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(INPUT_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            RandomSpecificRotation(),\n",
    "            transforms.ColorJitter(brightness=0.25, contrast=[0.25, 1.75], saturation=[0.75, 1.25], hue=0.04),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #inception\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(INPUT_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # inception\n",
    "        ]),\n",
    "        'test' : transforms.Compose([\n",
    "            transforms.Resize(INPUT_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # inception\n",
    "        ])\n",
    "    }\n",
    "else:\n",
    "     data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(INPUT_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            # RandomSpecificRotation(),\n",
    "            transforms.ColorJitter(brightness=0.25, contrast=[0.5, 1.75], saturation=[0.75, 1.25], hue=0.04)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(INPUT_SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "        'test' : transforms.Compose([\n",
    "            transforms.Resize(INPUT_SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c6f73b-5942-4513-bd16-2653038876fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training patches: 258108 \n",
      "Number of validation patches 58768 \n",
      "Number of test patches 47709\n"
     ]
    }
   ],
   "source": [
    "split=[70, 15, 15] # for splitting into train/val/test\n",
    "\n",
    "train_cases, val_cases, test_cases = split_data(img_dir, split, SEED)\n",
    "\n",
    "train_img_folders = [img_dir + case for case in train_cases]\n",
    "val_img_folders = [img_dir + case for case in val_cases]\n",
    "test_img_folders = [img_dir + case for case in test_cases]\n",
    "\n",
    "# Contains the file path for each .pt file for the cases used in each of the sets\n",
    "train_labels = [labels_dir + case + '.pt' for case in train_cases]\n",
    "val_labels = [labels_dir + case + '.pt' for case in val_cases]\n",
    "test_labels = [labels_dir + case + '.pt' for case in test_cases]\n",
    "\n",
    "image_datasets = {\n",
    "    'train': CustomDataset(train_img_folders, train_labels, transform=data_transforms['train']),\n",
    "    'val': CustomDataset(val_img_folders, val_labels, transform=data_transforms['val']),\n",
    "    'test': CustomDataset(test_img_folders, test_labels, transform=data_transforms['test'])\n",
    "}\n",
    "# Create training, validation and test dataloaders\n",
    "dataloaders = {\n",
    "    'train': data_utils.DataLoader(image_datasets['train'], batch_size=batch_size, num_workers=num_cpus, shuffle=True, drop_last=True),\n",
    "    'val': data_utils.DataLoader(image_datasets['val'], batch_size=batch_size, num_workers=num_cpus, shuffle=True),\n",
    "    'test': data_utils.DataLoader(image_datasets['test'], batch_size=batch_size, num_workers=num_cpus, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63af4e75-b15b-4e3c-b5cb-4ffd33a1deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_0 = 0\n",
    "total_1 = 0\n",
    "for batch in dataloaders['train']:\n",
    "    lbls = batch[2]\n",
    "    for lbl in lbls:\n",
    "        lbl = lbl.item()\n",
    "        if lbl==0:\n",
    "            total_0+=1\n",
    "        elif lbl==1:\n",
    "            total_1+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f1bf2d-f891-4f19-97a8-0d62ef3676dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class 0: 89743\n",
      "Total class 1: 168337\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total class 0: {total_0}\")\n",
    "print(f\"Total class 1: {total_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b821a-fc59-47a9-8589-f0879a70aebf",
   "metadata": {},
   "source": [
    "# Heatmap functions for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10965102-9a0b-4ec0-9483-b94255b2f4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
