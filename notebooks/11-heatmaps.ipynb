{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from openslide import open_slide\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch:\n",
    "    '''\n",
    "    Store properties of each patch\n",
    "    '''\n",
    "\n",
    "    def __init__(self, image, position, size=256):\n",
    "        self.image = image\n",
    "        self.position = position\n",
    "        self.size = size\n",
    "        self.probability = None\n",
    "        self.prediction = None\n",
    "        self.is_background = False\n",
    "    \n",
    "    def set_probability(self, probability):\n",
    "        self.probability = probability\n",
    "\n",
    "    def get_prediction(self):\n",
    "        self.prediction = 1 if self.probability >= 0.5 else 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tensor(tensor: torch.Tensor):\n",
    "    '''\n",
    "    Scale a tensor to the range [0, 1]\n",
    "    '''\n",
    "    minn = tensor.min()\n",
    "    maxx = tensor.max()\n",
    "    tensor = (tensor - minn)/(maxx - minn)\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    return tensor\n",
    "\n",
    "def image_to_patches_with_positions(image, patch_size: int, stride: int):\n",
    "    '''\n",
    "    Function for splitting an input image into patches.\n",
    "\n",
    "    Parameters:\n",
    "    image: input image to split\n",
    "    patch_size (int): dimension, patches will be square\n",
    "    stride (int): controls overlap between patches\n",
    "\n",
    "    Returns:\n",
    "    Tensor of patches with shape (num_patches, im_dim (if applicable), patch_size, patch_size) with their positions in the original image\n",
    "    '''\n",
    "    # Convert image to PyTorch tensor\n",
    "    im = torch.from_numpy(image)\n",
    "    # Scale image to [0, 1]\n",
    "    im = scale_tensor(im)\n",
    "\n",
    "    # Is image colour or binary?\n",
    "    image_dimension = 3 if len(image.shape) == 3 else 1\n",
    "    # Working with a colour image\n",
    "    if image_dimension == 3:\n",
    "        # Extract patches\n",
    "        patches = im.unfold(0, patch_size, stride).unfold(1, patch_size, stride)\n",
    "        # Reshape tensor into tensor of shape (num_patches, 3, patch_size, patch_size)\n",
    "        patches = patches.contiguous().view(-1, image_dimension, patch_size, patch_size) ###.contiguous() ensure tensor is stored in contiguous block of memory which is required for .view()\n",
    "    # Working with greyscale image\n",
    "    else:\n",
    "        # Extract patches\n",
    "        patches = im.unfold(0, patch_size, stride).unfold(1, patch_size, stride)\n",
    "        # Reshape tensor into tensor of shape (num_patches, patch_size, patch_size)\n",
    "        patches = patches.contiguous().view(-1, patch_size, patch_size)\n",
    "\n",
    "    # Calculate the number of patches in each dimension\n",
    "    height, width = image.shape[:2]\n",
    "    num_patches_h = (height - patch_size) // stride + 1\n",
    "    num_patches_w = (width - patch_size) // stride + 1\n",
    "\n",
    "    # Generate positions of the patches\n",
    "    positions = []\n",
    "    for h in range(num_patches_h):\n",
    "        for w in range(num_patches_w):\n",
    "            # Calculate the top-left position of the current patch\n",
    "            top = h * stride\n",
    "            left = w * stride\n",
    "            positions.append((top, left))\n",
    "\n",
    "    return patches, positions\n",
    "\n",
    "def get_patch_objects(patches, positions):\n",
    "    patch_objects = []\n",
    "    for patch, position in zip(patches, positions):\n",
    "        patch_object = Patch(image=patch, position=position)\n",
    "        patch_objects.append(patch_object)\n",
    "    return patch_objects\n",
    "\n",
    "## CHECK THIS FUNCTION PROPERLY for my data\n",
    "def check_if_background(patch):\n",
    "    '''\n",
    "    Given a patch, return whether it should be classified as a background patch or not.\n",
    "    '''\n",
    "    # working with actual patch now and NOT the mask?????????????????\n",
    "    im = np.array(patch.convert(mode='RGB'))\n",
    "    pixels = np.ravel(im)\n",
    "    mean = np.mean(pixels)\n",
    "    is_background = mean >= 220\n",
    "    return is_background\n",
    "\n",
    "def choose_random_image(directory, seed):\n",
    "    '''\n",
    "    Choose a SVS file randomly to perform inference and produce heatmap.\n",
    "\n",
    "    Return level 1 image from SVS file as well as the images case code.\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    files = os.listdir(directory)\n",
    "    svs_files = [file for file in files if file.endswith(('.svs'))]\n",
    "    # Randomly choose file\n",
    "    random_svs = random.choice(svs_files)\n",
    "    print(random_svs)\n",
    "    name = random_svs.replace('.svs', '')\n",
    "    if name.startswith('._'):\n",
    "        name = name.replace('._', '')\n",
    "    case_code = name.split('.')[0].replace('TCGA-', '').replace('-01Z-00-DX1', '')\n",
    "    slide_path = os.path.join(directory, random_svs)\n",
    "    sld = open_slide(slide_path)\n",
    "    slide_props = sld.properties\n",
    "    slide_width = int(slide_props['openslide.level[1].width']); slide_height = int(slide_props['openslide.level[1].height']) # dimensions at 10X magnification\n",
    "    slide = np.array(sld.get_thumbnail(size=(slide_width, slide_height)))\n",
    "\n",
    "    return case_code, slide\n",
    "\n",
    "def check_seg_accuracy(label_directory, case_code):\n",
    "    # get image labels for \n",
    "    # going to run into problem: what if there arent the same number of background patches as this algorithm returns - wont be able to calculate accuracy\n",
    "    return acc\n",
    "\n",
    "def get_prediction(patch, output):\n",
    "    # preprocess\n",
    "\n",
    "    # get predictions for patch\n",
    "    probabilities = torch.softmax(output, dim=1) # Post-process the predictions\n",
    "    patch.probability = probabilities[1]\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    patch.prediction = predicted_class\n",
    "\n",
    "def create_heatmap(image_size, patches):\n",
    "    '''\n",
    "    Generate the heatmap array based on patch predicted probabilities.\n",
    "    '''\n",
    "    heat_map = np.zeros(image_size)\n",
    "    for patch in patches:\n",
    "        i, j = patch.position\n",
    "        h, w = patch.size\n",
    "        heat_map[i:i+h, j+j+w] = patch.probability\n",
    "\n",
    "def inference(patches, model):\n",
    "    '''\n",
    "    Takes in Patch objects and makes predictions for each patch if it is not classified as a background patch.\n",
    "    Then uses those predictions to create a heatmap\n",
    "    '''\n",
    "    model.eval()\n",
    "    for patch in patches:\n",
    "        is_background = check_if_background(patch.patch)\n",
    "        if not is_background:\n",
    "            output = model.predict(patch.image)\n",
    "            get_prediction(patch, output)\n",
    "        else:\n",
    "            patch.probability = 0\n",
    "            patch.prediction = 0\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def visualise_heatmap():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE=256\n",
    "STRIDE=PATCH_SIZE\n",
    "num_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "images_directory = '/Volumes/AlexS/MastersData/SVS files/'\n",
    "labels_directory = '/Volumes/AlexS/MastersData/processed/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image = choose_random_image(images_directory, SEED)\n",
    "image_size = image.shape\n",
    "# extract patches\n",
    "patches, positions = image_to_patches_with_positions(image, PATCH_SIZE, STRIDE)\n",
    "# create Patch objects\n",
    "patch_objects = get_patch_objects(patches, positions)\n",
    "heatmap = inference(patch_objects)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Want to be able to overlay this produced heatmap over the original slide\n",
    "- Also need to create heatmap of the original slide with its classes to visualise what is the ground truth segmentation using patches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
