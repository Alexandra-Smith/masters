{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from openslide import open_slide\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom PyTorch dataset to read in your images and apply transforms\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_folders, label_files, transform=None):\n",
    "        self.img_folders = img_folders\n",
    "        self.label_files = label_files\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs = [] # Keeps image paths to load in the __getitem__ method\n",
    "        self.labels = []\n",
    "\n",
    "        # Load images and corresponding labels\n",
    "        for i, (img_folder, label_file) in enumerate(zip(img_folders, label_files)):\n",
    "            # print(\"Patch directory\", img_folder, \"\\nLabel file\", label_file)\n",
    "            labels_pt = torch.load(label_file) # Load .pt file\n",
    "            # Run through all patches from the case folder\n",
    "            for i, img in enumerate(os.listdir(img_folder)):\n",
    "                if os.path.isfile(img_folder + '/' + img) and os.path.isfile(label_file):\n",
    "                    # print(img_folder + img)\n",
    "                    if img.startswith('._'):\n",
    "                        img = img.replace('._', '')\n",
    "                    idx = int(img.replace('.png', '').split(\"_\")[1])\n",
    "                    self.imgs.append(img_folder + '/' + img)\n",
    "                    self.labels.append(labels_pt[idx].item()) # get label as int\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image at given index\n",
    "        image_path = self.imgs[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None: # Apply transformations\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx] # Load corresponding image label\n",
    "        \n",
    "        return image, label # Return transformed image and label\n",
    "\n",
    "# Split image folders into train, val, test\n",
    "def split_data(patch_directory, split: list, seed):\n",
    "    '''\n",
    "    Function that takes in the split percentage for train/val/test sets, and randomly chooses which cases\n",
    "    to allocate to which set (to ensure all patches from one case go into one set)\n",
    "    Parameters:\n",
    "    patch_directory: folder containing all patches\n",
    "    split: list of integers for splitting sets\n",
    "    seed: option to set the seed value for randomness\n",
    "    Returns:\n",
    "    3 lists for each of train/val/test, where each list contains the case names to be used in the set\n",
    "    '''\n",
    "    \n",
    "    random.seed(seed)\n",
    "\n",
    "    case_folders = os.listdir(patch_directory) # get 147 case folders\n",
    "    \n",
    "    d = {}\n",
    "    for folder in case_folders:\n",
    "        num_patches_in_folder = len(os.listdir(patch_directory + folder))\n",
    "        d[folder] = num_patches_in_folder\n",
    "    \n",
    "    total_num_patches = sum(d.values())\n",
    "    train_split, val_split, test_split = split\n",
    "    train_num_patches = int((train_split/100)*total_num_patches)\n",
    "    val_num_patches = int((val_split/100)*total_num_patches)\n",
    "\n",
    "    # list all folders in the directory\n",
    "    folders = [os.path.join(patch_directory, folder) for folder in os.listdir(patch_directory) if os.path.isdir(os.path.join(patch_directory, folder))]\n",
    "    \n",
    "    # SELECT TRAINING CASES\n",
    "    train_cases = [] # store all selected cases\n",
    "    num_selected_train = 0 # number of patches selected so far\n",
    "    selected_folders = set() # a set to store the selected folder names to keep track of those already selected\n",
    "    while num_selected_train < train_num_patches:\n",
    "        folder = random.choice(folders)\n",
    "        if folder not in selected_folders:\n",
    "            case = folder.replace(patch_directory, '')\n",
    "            num_patches = len(os.listdir(folder))\n",
    "            num_selected_train += num_patches\n",
    "            selected_folders.add(folder) # add to set of selected folders\n",
    "            train_cases.append(case)\n",
    "\n",
    "    # SELECT VAL CASES\n",
    "    val_cases = [] # store all selected cases\n",
    "    num_selected_val = 0 # number of patches selected so far\n",
    "    while num_selected_val < val_num_patches:\n",
    "        folder = random.choice(folders)\n",
    "        if folder not in selected_folders:\n",
    "            case = folder.replace(patch_directory, '')\n",
    "            num_patches = len(os.listdir(folder))\n",
    "            num_selected_val += num_patches\n",
    "            selected_folders.add(folder)\n",
    "            val_cases.append(case)\n",
    "\n",
    "    # SELECT TEST CASES\n",
    "    cases = [folder.replace(patch_directory, '') for folder in folders]\n",
    "    used = train_cases+val_cases\n",
    "    test_cases = [case for case in cases if case not in used]\n",
    "    \n",
    "    # test_patches = [len(os.listdir(patch_directory + folder)) for folder in test_cases]\n",
    "    num_selected_test = sum([len(os.listdir(patch_directory + folder)) for folder in test_cases])\n",
    "    # dict = {x: for x in ['train', 'val', 'test']}\n",
    "    print(f\"Number of training patches: {num_selected_train} \\nNumber of validation patches {num_selected_val} \\nNumber of test patches {num_selected_test}\")\n",
    "    return train_cases, val_cases, test_cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tensor(tensor: torch.Tensor):\n",
    "    '''\n",
    "    Scale a tensor to the range [0, 1]\n",
    "    '''\n",
    "    minn = tensor.min()\n",
    "    maxx = tensor.max()\n",
    "    tensor = (tensor - minn)/(maxx - minn)\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    return tensor\n",
    "\n",
    "def image_to_patches(image, patch_size: int, stride: int):\n",
    "    '''\n",
    "    Function for splitting an input image into patches.\n",
    "\n",
    "    Parameters:\n",
    "    image: input image to split\n",
    "    patch_size (int): dimension, patches will be square\n",
    "    stride (int): controls overlap between patches\n",
    "\n",
    "    Returns:\n",
    "    Tensor of patches with shape (num_patches, im_dim (if applicable), patch_size, patch_size)\n",
    "    '''\n",
    "    # Convert image to PyTorch tensor\n",
    "    im = torch.from_numpy(image)\n",
    "    # Scale image to [0, 1]\n",
    "    im = scale_tensor(im)\n",
    "\n",
    "    # Is image colour or binary?\n",
    "    image_dimension = 3 if len(image.shape) == 3 else 1\n",
    "    # Working with a colour image\n",
    "    if image_dimension == 3:\n",
    "        # Extract patches\n",
    "        patches = im.unfold(0, patch_size, stride).unfold(1, patch_size, stride)\n",
    "        # Reshape tensor into tensor of shape (num_patches, 3, patch_size, patch_size)\n",
    "        patches = patches.contiguous().view(-1, image_dimension, patch_size, patch_size) ###.contiguous() ensure tensor is stored in contiguous block of memory which is required for .view()\n",
    "        # - Can also reshape patches into a 2D tensor, where each row is a flattened patch\n",
    "        # - patches = patches.contiguous().view(-1, patch_size*patch_size)\n",
    "    # Working with greyscale image\n",
    "    else:\n",
    "        # Extract patches\n",
    "        patches = im.unfold(0, patch_size, stride).unfold(1, patch_size, stride)\n",
    "        # Reshape tensor into tensor of shape (num_patches, patch_size, patch_size)\n",
    "        patches = patches.contiguous().view(-1, patch_size, patch_size)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def check_if_background(patch):\n",
    "    '''\n",
    "    Given a patch, return whether it should be classified as a patch or not.\n",
    "    '''\n",
    "    p = patch.numpy()\n",
    "    # working with actual patch now and NOT the mask?????????????????\n",
    "    nwhite_px = np.sum(p == 1); ngrey_px = np.sum(p == 0.5)\n",
    "\n",
    "    return is_background"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
