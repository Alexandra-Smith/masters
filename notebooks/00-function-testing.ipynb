{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8a26ee",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9214dc7-bdb4-4434-9355-e4ac271793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys \n",
    "sys.path.append('/home/21576262@su/masters/src')\n",
    "from data.data_loading import CustomDataset, define_transforms, split_data\n",
    "from data.get_data import split_tumour_data, HER2Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.utils.data as data_utils\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5275735a-02b9-4be2-9430-9ffb3333e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364585\n"
     ]
    }
   ],
   "source": [
    "# Check total number of patches available\n",
    "img_dir = '/home/21576262@su/masters/data/patches/'\n",
    "\n",
    "folders = os.listdir(img_dir)\n",
    "tt=0\n",
    "for folder in folders:\n",
    "    tt+=(len(os.listdir(img_dir + folder)))\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cdce17c-2856-42fb-b903-65f2e0d7c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tumour patches: 232506 \n",
      "Number of training patches: 163471 \n",
      "Number of validation patches 35335 \n",
      "Number of test patches 33700\n"
     ]
    }
   ],
   "source": [
    "# using full set of data\n",
    "img_dir = '/home/21576262@su/masters/data/patches/'\n",
    "labels_dir = '/home/21576262@su/masters/data/labels/' \n",
    "\n",
    "SEED=42\n",
    "\n",
    "split=[70, 15, 15] # for splitting into train/val/test\n",
    "\n",
    "train_cases, val_cases, test_cases = split_tumour_data(img_dir, labels_dir, split, SEED)\n",
    "# train_cases, val_cases, test_cases = split_data(img_dir, split, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176a145-c4c1-45bc-b76a-a722aee46f3f",
   "metadata": {},
   "source": [
    "Note! this is counting all tumour patches, but some of these may have been removed by me when manually removing some tiles therefore this total may not be completely correct\n",
    "-> this is actually okay because the split isn't exact anyway when taking into account the data leaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a838673e-12ad-4da9-806f-5d70b369bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_folders = [img_dir + case for case in train_cases]\n",
    "val_img_folders = [img_dir + case for case in val_cases]\n",
    "test_img_folders = [img_dir + case for case in test_cases]\n",
    "\n",
    "# Contains the file path for each .pt file for the cases used in each of the sets\n",
    "train_labels = [labels_dir + case + '.pt' for case in train_cases]\n",
    "val_labels = [labels_dir + case + '.pt' for case in val_cases]\n",
    "test_labels = [labels_dir + case + '.pt' for case in test_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b1aca79-0b06-4c21-a9fb-1d7a5756cf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 29 21\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img_folders), len(val_img_folders), len(test_img_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8867156-d432-48f7-97a2-4fad7457af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = define_transforms(256, isInception=True, isInceptionResnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed2a58c0-de7b-4b44-a45a-05a81b1932b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': CustomDataset(train_img_folders, train_labels, transform=data_transforms['train']),\n",
    "    'val': CustomDataset(val_img_folders, val_labels, transform=data_transforms['val']),\n",
    "    'test': CustomDataset(test_img_folders, test_labels, transform=data_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3f408b-e8be-44fe-9b82-7dbbde79d157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251884\n",
      "56484\n",
      "56217\n"
     ]
    }
   ],
   "source": [
    "print(len(image_datasets['train']))\n",
    "print(len(image_datasets['val']))\n",
    "print(len(image_datasets['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eec757fc-be49-469f-b5e7-6399a57a9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': HER2Dataset(train_img_folders, train_labels, transform=data_transforms['train']),\n",
    "    'val': HER2Dataset(val_img_folders, val_labels, transform=data_transforms['val']),\n",
    "    'test': HER2Dataset(test_img_folders, test_labels, transform=data_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7b84cb6-0b1c-4228-bbb9-7276ee8edc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163047\n",
      "35180\n",
      "33620\n"
     ]
    }
   ],
   "source": [
    "print(len(image_datasets['train']))\n",
    "print(len(image_datasets['val']))\n",
    "print(len(image_datasets['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba7be7-0452-4209-98e4-b16036cb0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_0=0\n",
    "num_1=0\n",
    "for sample in image_datasets['train']:\n",
    "    if sample[1]==0:\n",
    "        num_0+=1\n",
    "    elif sample[1]==1:\n",
    "        num_1+=1\n",
    "print(num_0)\n",
    "print(num_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3ef5-a3e4-496c-9bcc-73f5eea15c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training, validation and test dataloaders\n",
    "    dataloaders = {\n",
    "        'train': data_utils.DataLoader(image_datasets['train'], batch_size=batch_size, num_workers=num_cpus, shuffle=True, drop_last=True),\n",
    "        'val': data_utils.DataLoader(image_datasets['val'], batch_size=batch_size, num_workers=num_cpus, shuffle=True),\n",
    "        'test': data_utils.DataLoader(image_datasets['test'], batch_size=batch_size, num_workers=num_cpus, shuffle=True)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
